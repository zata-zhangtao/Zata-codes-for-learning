{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6de8faf",
   "metadata": {},
   "source": [
    "# LangChain 调用 MCP 详细使用教程\n",
    "\n",
    "## 什么是 MCP (Model Context Protocol)？\n",
    "\n",
    "MCP（Model Context Protocol，模型上下文协议）是一个开放标准协议，旨在规范大型语言模型 (LLM) 与外部工具、数据源和服务交互的方式。它由 Anthropic 提出，并被 LangChain 等框架采纳，以增强 AI 应用的能力。\n",
    "\n",
    "MCP 的核心思想是创建一个客户端-服务器架构：\n",
    "\n",
    "* **MCP 服务器 (MCP Server)**：这些服务器暴露一组可供 LLM 使用的工具或数据接口。例如，一个 MCP 服务器可以提供数学计算工具、文件系统操作工具、天气查询API接口等。\n",
    "* **MCP 客户端 (MCP Client)**：通常是 LLM 应用或代理 (Agent)，它们连接到 MCP 服务器以使用其提供的工具来完成特定任务。\n",
    "\n",
    "通过 MCP，开发者可以构建更强大、更具互操作性的 AI 系统，使得 LLM 能够安全、可控地访问和利用外部世界的信息与能力。\n",
    "\n",
    "## LangChain 与 MCP 的集成\n",
    "\n",
    "LangChain 提供了与 MCP 生态系统集成的能力，主要通过以下库：\n",
    "\n",
    "* `mcp`: 用于创建 MCP 服务器的 Python 库（例如，使用 `FastMCP` 可以快速定义和运行 MCP 服务器）。\n",
    "* `langchain-mcp-adapters`: 这个库使得 LangChain (特别是 LangGraph Agents) 能够作为 MCP 客户端，发现并使用 MCP 服务器上定义的工具。\n",
    "\n",
    "本教程将引导你完成以下步骤：\n",
    "\n",
    "1.  安装必要的库。\n",
    "2.  创建一个简单的 MCP 服务器，该服务器提供一些基本工具。\n",
    "3.  创建一个 LangChain 代理 (Agent)，该代理能够调用 MCP 服务器上的工具。\n",
    "4.  运行并测试整个流程。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bd03fd",
   "metadata": {},
   "source": [
    "## 步骤 1: 安装必要的库\n",
    "\n",
    "首先，你需要安装 LangChain 核心库、用于创建 MCP 服务器的库、MCP 适配器库以及一个 LLM 提供商的库（本例中我们将使用 `langchain-openai`，你可以根据需要替换）。\n",
    "\n",
    "```bash\n",
    "pip install langchain langchain-openai langchain-mcp-adapters mcp\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b441e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.25-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.3.16-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langchain-mcp-adapters\n",
      "  Downloading langchain_mcp_adapters-0.0.11-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting mcp\n",
      "  Using cached mcp-1.8.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.58 (from langchain)\n",
      "  Downloading langchain_core-0.3.59-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.3.42-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Downloading pydantic-2.11.4-py3-none-any.whl.metadata (66 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading sqlalchemy-2.0.40-cp313-cp313-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting requests<3,>=2 (from langchain)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain)\n",
      "  Downloading PyYAML-6.0.2-cp313-cp313-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.58->langchain)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.58->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core<1.0.0,>=0.3.58->langchain)\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\zata\\.conda\\envs\\langchian\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.13.2)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.18-cp313-cp313-win_amd64.whl.metadata (43 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading zstandard-0.23.0-cp313-cp313-win_amd64.whl.metadata (3.0 kB)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading pydantic_core-2.33.2-cp313-cp313-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langchain)\n",
      "  Downloading charset_normalizer-3.4.2-cp313-cp313-win_amd64.whl.metadata (36 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain)\n",
      "  Using cached urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.2.2-cp313-cp313-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting openai<2.0.0,>=1.68.2 (from langchain-openai)\n",
      "  Downloading openai-1.78.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
      "  Downloading tiktoken-0.9.0-cp313-cp313-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.68.2->langchain-openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.68.2->langchain-openai)\n",
      "  Downloading jiter-0.9.0-cp313-cp313-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting sniffio (from openai<2.0.0,>=1.68.2->langchain-openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai<2.0.0,>=1.68.2->langchain-openai)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai)\n",
      "  Downloading regex-2024.11.6-cp313-cp313-win_amd64.whl.metadata (41 kB)\n",
      "Collecting httpx-sse>=0.4 (from mcp)\n",
      "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting pydantic-settings>=2.5.2 (from mcp)\n",
      "  Using cached pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting python-multipart>=0.0.9 (from mcp)\n",
      "  Using cached python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting sse-starlette>=1.6.1 (from mcp)\n",
      "  Using cached sse_starlette-2.3.4-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting starlette>=0.27 (from mcp)\n",
      "  Using cached starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting uvicorn>=0.23.1 (from mcp)\n",
      "  Using cached uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings>=2.5.2->mcp)\n",
      "  Using cached python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\zata\\.conda\\envs\\langchian\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.68.2->langchain-openai) (0.4.6)\n",
      "Collecting click>=7.0 (from uvicorn>=0.23.1->mcp)\n",
      "  Using cached click-8.2.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Downloading langchain-0.3.25-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 7.9 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.3.59-py3-none-any.whl (437 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading langsmith-0.3.42-py3-none-any.whl (360 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading orjson-3.10.18-cp313-cp313-win_amd64.whl (134 kB)\n",
      "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Downloading pydantic-2.11.4-py3-none-any.whl (443 kB)\n",
      "Downloading pydantic_core-2.33.2-cp313-cp313-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 17.6 MB/s eta 0:00:00\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.2-cp313-cp313-win_amd64.whl (105 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading sqlalchemy-2.0.40-cp313-cp313-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/2.1 MB 12.3 MB/s eta 0:00:00\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Downloading zstandard-0.23.0-cp313-cp313-win_amd64.whl (495 kB)\n",
      "Downloading langchain_openai-0.3.16-py3-none-any.whl (62 kB)\n",
      "Downloading openai-1.78.0-py3-none-any.whl (680 kB)\n",
      "   ---------------------------------------- 0.0/680.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 680.4/680.4 kB 10.3 MB/s eta 0:00:00\n",
      "Using cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.9.0-cp313-cp313-win_amd64.whl (204 kB)\n",
      "Downloading tiktoken-0.9.0-cp313-cp313-win_amd64.whl (894 kB)\n",
      "   ---------------------------------------- 0.0/894.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 894.7/894.7 kB 25.4 MB/s eta 0:00:00\n",
      "Downloading langchain_mcp_adapters-0.0.11-py3-none-any.whl (10 kB)\n",
      "Using cached mcp-1.8.0-py3-none-any.whl (119 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
      "Downloading greenlet-3.2.2-cp313-cp313-win_amd64.whl (296 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
      "Using cached python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Using cached python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading PyYAML-6.0.2-cp313-cp313-win_amd64.whl (156 kB)\n",
      "Downloading regex-2024.11.6-cp313-cp313-win_amd64.whl (273 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached sse_starlette-2.3.4-py3-none-any.whl (10 kB)\n",
      "Using cached starlette-0.46.2-py3-none-any.whl (72 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Using cached uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
      "Using cached click-8.2.0-py3-none-any.whl (102 kB)\n",
      "Installing collected packages: zstandard, urllib3, typing-inspection, tqdm, tenacity, sniffio, regex, PyYAML, python-multipart, python-dotenv, pydantic-core, packaging, orjson, jsonpointer, jiter, idna, httpx-sse, h11, greenlet, distro, click, charset-normalizer, certifi, annotated-types, uvicorn, SQLAlchemy, requests, pydantic, jsonpatch, httpcore, anyio, tiktoken, starlette, requests-toolbelt, pydantic-settings, httpx, sse-starlette, openai, langsmith, mcp, langchain-core, langchain-text-splitters, langchain-openai, langchain-mcp-adapters, langchain\n",
      "\n",
      "    ---------------------------------------  1/45 [urllib3]\n",
      "    ---------------------------------------  1/45 [urllib3]\n",
      "    ---------------------------------------  1/45 [urllib3]\n",
      "   -- -------------------------------------  3/45 [tqdm]\n",
      "   -- -------------------------------------  3/45 [tqdm]\n",
      "   -- -------------------------------------  3/45 [tqdm]\n",
      "   --- ------------------------------------  4/45 [tenacity]\n",
      "   ----- ----------------------------------  6/45 [regex]\n",
      "   ------ ---------------------------------  7/45 [PyYAML]\n",
      "   ------ ---------------------------------  7/45 [PyYAML]\n",
      "   -------- -------------------------------  9/45 [python-dotenv]\n",
      "   -------- ------------------------------- 10/45 [pydantic-core]\n",
      "  Attempting uninstall: packaging\n",
      "   -------- ------------------------------- 10/45 [pydantic-core]\n",
      "    Found existing installation: packaging 25.0\n",
      "   -------- ------------------------------- 10/45 [pydantic-core]\n",
      "    Uninstalling packaging-25.0:\n",
      "   -------- ------------------------------- 10/45 [pydantic-core]\n",
      "      Successfully uninstalled packaging-25.0\n",
      "   -------- ------------------------------- 10/45 [pydantic-core]\n",
      "   --------- ------------------------------ 11/45 [packaging]\n",
      "   --------- ------------------------------ 11/45 [packaging]\n",
      "   ----------- ---------------------------- 13/45 [jsonpointer]\n",
      "   ------------- -------------------------- 15/45 [idna]\n",
      "   -------------- ------------------------- 16/45 [httpx-sse]\n",
      "   ---------------- ----------------------- 18/45 [greenlet]\n",
      "   ---------------- ----------------------- 18/45 [greenlet]\n",
      "   ---------------- ----------------------- 18/45 [greenlet]\n",
      "   ---------------- ----------------------- 19/45 [distro]\n",
      "   ----------------- ---------------------- 20/45 [click]\n",
      "   ------------------ --------------------- 21/45 [charset-normalizer]\n",
      "   ------------------- -------------------- 22/45 [certifi]\n",
      "   --------------------- ------------------ 24/45 [uvicorn]\n",
      "   --------------------- ------------------ 24/45 [uvicorn]\n",
      "   --------------------- ------------------ 24/45 [uvicorn]\n",
      "   ---------------------- ----------------- 25/45 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/45 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/45 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/45 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/45 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/45 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/45 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/45 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/45 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/45 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/45 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/45 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/45 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/45 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/45 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/45 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/45 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/45 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/45 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/45 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/45 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/45 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/45 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/45 [SQLAlchemy]\n",
      "   ----------------------- ---------------- 26/45 [requests]\n",
      "   ------------------------ --------------- 27/45 [pydantic]\n",
      "   ------------------------ --------------- 27/45 [pydantic]\n",
      "   ------------------------ --------------- 27/45 [pydantic]\n",
      "   ------------------------ --------------- 27/45 [pydantic]\n",
      "   ------------------------ --------------- 27/45 [pydantic]\n",
      "   ------------------------ --------------- 27/45 [pydantic]\n",
      "   ------------------------ --------------- 27/45 [pydantic]\n",
      "   ------------------------ --------------- 27/45 [pydantic]\n",
      "   ------------------------ --------------- 27/45 [pydantic]\n",
      "   ------------------------ --------------- 27/45 [pydantic]\n",
      "   ------------------------- -------------- 29/45 [httpcore]\n",
      "   ------------------------- -------------- 29/45 [httpcore]\n",
      "   -------------------------- ------------- 30/45 [anyio]\n",
      "   -------------------------- ------------- 30/45 [anyio]\n",
      "   --------------------------- ------------ 31/45 [tiktoken]\n",
      "   ---------------------------- ----------- 32/45 [starlette]\n",
      "   ---------------------------- ----------- 32/45 [starlette]\n",
      "   ----------------------------- ---------- 33/45 [requests-toolbelt]\n",
      "   ------------------------------ --------- 34/45 [pydantic-settings]\n",
      "   ------------------------------ --------- 34/45 [pydantic-settings]\n",
      "   ------------------------------- -------- 35/45 [httpx]\n",
      "   ------------------------------- -------- 35/45 [httpx]\n",
      "   ------------------------------- -------- 35/45 [httpx]\n",
      "   -------------------------------- ------- 37/45 [openai]\n",
      "   -------------------------------- ------- 37/45 [openai]\n",
      "   -------------------------------- ------- 37/45 [openai]\n",
      "   -------------------------------- ------- 37/45 [openai]\n",
      "   -------------------------------- ------- 37/45 [openai]\n",
      "   -------------------------------- ------- 37/45 [openai]\n",
      "   -------------------------------- ------- 37/45 [openai]\n",
      "   -------------------------------- ------- 37/45 [openai]\n",
      "   -------------------------------- ------- 37/45 [openai]\n",
      "   -------------------------------- ------- 37/45 [openai]\n",
      "   -------------------------------- ------- 37/45 [openai]\n",
      "   -------------------------------- ------- 37/45 [openai]\n",
      "   -------------------------------- ------- 37/45 [openai]\n",
      "   -------------------------------- ------- 37/45 [openai]\n",
      "   -------------------------------- ------- 37/45 [openai]\n",
      "   -------------------------------- ------- 37/45 [openai]\n",
      "   -------------------------------- ------- 37/45 [openai]\n",
      "   -------------------------------- ------- 37/45 [openai]\n",
      "   -------------------------------- ------- 37/45 [openai]\n",
      "   -------------------------------- ------- 37/45 [openai]\n",
      "   -------------------------------- ------- 37/45 [openai]\n",
      "   -------------------------------- ------- 37/45 [openai]\n",
      "   -------------------------------- ------- 37/45 [openai]\n",
      "   -------------------------------- ------- 37/45 [openai]\n",
      "   -------------------------------- ------- 37/45 [openai]\n",
      "   -------------------------------- ------- 37/45 [openai]\n",
      "   -------------------------------- ------- 37/45 [openai]\n",
      "   -------------------------------- ------- 37/45 [openai]\n",
      "   -------------------------------- ------- 37/45 [openai]\n",
      "   -------------------------------- ------- 37/45 [openai]\n",
      "   -------------------------------- ------- 37/45 [openai]\n",
      "   -------------------------------- ------- 37/45 [openai]\n",
      "   -------------------------------- ------- 37/45 [openai]\n",
      "   -------------------------------- ------- 37/45 [openai]\n",
      "   -------------------------------- ------- 37/45 [openai]\n",
      "   --------------------------------- ------ 38/45 [langsmith]\n",
      "   --------------------------------- ------ 38/45 [langsmith]\n",
      "   --------------------------------- ------ 38/45 [langsmith]\n",
      "   --------------------------------- ------ 38/45 [langsmith]\n",
      "   ---------------------------------- ----- 39/45 [mcp]\n",
      "   ---------------------------------- ----- 39/45 [mcp]\n",
      "   ---------------------------------- ----- 39/45 [mcp]\n",
      "   ---------------------------------- ----- 39/45 [mcp]\n",
      "   ---------------------------------- ----- 39/45 [mcp]\n",
      "   ----------------------------------- ---- 40/45 [langchain-core]\n",
      "   ----------------------------------- ---- 40/45 [langchain-core]\n",
      "   ----------------------------------- ---- 40/45 [langchain-core]\n",
      "   ----------------------------------- ---- 40/45 [langchain-core]\n",
      "   ----------------------------------- ---- 40/45 [langchain-core]\n",
      "   ----------------------------------- ---- 40/45 [langchain-core]\n",
      "   ----------------------------------- ---- 40/45 [langchain-core]\n",
      "   ----------------------------------- ---- 40/45 [langchain-core]\n",
      "   ----------------------------------- ---- 40/45 [langchain-core]\n",
      "   ----------------------------------- ---- 40/45 [langchain-core]\n",
      "   ----------------------------------- ---- 40/45 [langchain-core]\n",
      "   ------------------------------------ --- 41/45 [langchain-text-splitters]\n",
      "   ------------------------------------- -- 42/45 [langchain-openai]\n",
      "   ------------------------------------- -- 42/45 [langchain-openai]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain]\n",
      "   ---------------------------------------- 45/45 [langchain]\n",
      "\n",
      "Successfully installed PyYAML-6.0.2 SQLAlchemy-2.0.40 annotated-types-0.7.0 anyio-4.9.0 certifi-2025.4.26 charset-normalizer-3.4.2 click-8.2.0 distro-1.9.0 greenlet-3.2.2 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 httpx-sse-0.4.0 idna-3.10 jiter-0.9.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.25 langchain-core-0.3.59 langchain-mcp-adapters-0.0.11 langchain-openai-0.3.16 langchain-text-splitters-0.3.8 langsmith-0.3.42 mcp-1.8.0 openai-1.78.0 orjson-3.10.18 packaging-24.2 pydantic-2.11.4 pydantic-core-2.33.2 pydantic-settings-2.9.1 python-dotenv-1.1.0 python-multipart-0.0.20 regex-2024.11.6 requests-2.32.3 requests-toolbelt-1.0.0 sniffio-1.3.1 sse-starlette-2.3.4 starlette-0.46.2 tenacity-9.1.2 tiktoken-0.9.0 tqdm-4.67.1 typing-inspection-0.4.0 urllib3-2.4.0 uvicorn-0.34.2 zstandard-0.23.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-openai langchain-mcp-adapters mcp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602c0d16",
   "metadata": {},
   "source": [
    "## 步骤 2: 创建一个简单的 MCP 服务器\n",
    "我们将创建一个 MCP 服务器，它提供两个简单的数学工具：add (加法) 和 multiply (乘法)。\n",
    "\n",
    "创建一个名为 mcp_server.py 的 Python 文件，并添加以下内容："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42718ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nest_asyncio in c:\\users\\zata\\.conda\\envs\\langchian\\lib\\site-packages (1.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79054db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coroutine object main at 0x000001FBAE7C0040>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mcp_server.py\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "import asyncio\n",
    "\n",
    "# 创建一个 FastMCP 实例，并命名为 \"MathServer\"\n",
    "mcp_server = FastMCP(name=\"MathServer\", description=\"A simple server with math tools.\")\n",
    "\n",
    "# 定义一个工具：加法\n",
    "@mcp_server.tool()\n",
    "async def add(a: int, b: int) -> int:\n",
    "    \"\"\"\n",
    "    Adds two integers.\n",
    "    For example: add(a=5, b=3) would return 8.\n",
    "    \"\"\"\n",
    "    print(f\"[MCP Server] Received add request: a={a}, b={b}\")\n",
    "    result = a + b\n",
    "    print(f\"[MCP Server] Sending add response: {result}\")\n",
    "    return result\n",
    "\n",
    "# 定义另一个工具：乘法\n",
    "@mcp_server.tool()\n",
    "async def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"\n",
    "    Multiplies two integers.\n",
    "    For example: multiply(a=5, b=3) would return 15.\n",
    "    \"\"\"\n",
    "    print(f\"[MCP Server] Received multiply request: a={a}, b={b}\")\n",
    "    result = a * b\n",
    "    print(f\"[MCP Server] Sending multiply response: {result}\")\n",
    "    return result\n",
    "\n",
    "async def main():\n",
    "    # 运行 MCP 服务器，使用 stdio 作为传输方式\n",
    "    # 这意味着服务器将通过标准输入/输出与客户端通信\n",
    "    # 对于生产环境，你可能会使用 HTTP 或其他网络传输方式\n",
    "    print(\"[MCP Server] Starting MathServer on stdio...\")\n",
    "    await mcp_server.run(transport=\"stdio\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     asyncio.run(main())\n",
    "\n",
    "main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9752134b",
   "metadata": {},
   "source": [
    "说明:\n",
    "\n",
    "FastMCP: 提供了一种快速定义工具和运行服务器的方式。\n",
    "@mcp_server.tool(): 装饰器将一个 Python 函数注册为 MCP 服务器上的一个可用工具。函数的类型注解和文档字符串 (docstring) 非常重要，因为它们会被 MCP 客户端用来理解如何调用该工具以及工具的功能。\n",
    "transport=\"stdio\": 这里我们使用 stdio (标准输入/输出) 作为服务器和客户端之间的通信方式。这意味着服务器进程将通过其标准输入接收请求，并通过标准输出发送响应。这对于本地测试很方便。在实际部署中，你可能会使用 HTTP 等网络协议。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d931c4",
   "metadata": {},
   "source": [
    "## 步骤 3: 创建 LangChain 代理以调用 MCP 工具\n",
    "现在，我们将创建一个 LangChain 代理，它能够连接到我们刚刚创建的 MathServer 并使用其提供的 add 和 multiply 工具。\n",
    "\n",
    "创建一个名为 langchain_mcp_client.py 的 Python 文件，并添加以下内容："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c965ea81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-mcp-adapters in c:\\users\\zata\\.conda\\envs\\langchian\\lib\\site-packages (0.0.11)\n",
      "Collecting langgraph\n",
      "  Downloading langgraph-0.4.3-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.3.36 in c:\\users\\zata\\.conda\\envs\\langchian\\lib\\site-packages (from langchain-mcp-adapters) (0.3.59)\n",
      "Requirement already satisfied: mcp>=1.7 in c:\\users\\zata\\.conda\\envs\\langchian\\lib\\site-packages (from langchain-mcp-adapters) (1.8.0)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\zata\\.conda\\envs\\langchian\\lib\\site-packages (from langchain-core<0.4,>=0.3.36->langchain-mcp-adapters) (0.3.42)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\zata\\.conda\\envs\\langchian\\lib\\site-packages (from langchain-core<0.4,>=0.3.36->langchain-mcp-adapters) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\zata\\.conda\\envs\\langchian\\lib\\site-packages (from langchain-core<0.4,>=0.3.36->langchain-mcp-adapters) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\zata\\.conda\\envs\\langchian\\lib\\site-packages (from langchain-core<0.4,>=0.3.36->langchain-mcp-adapters) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\zata\\.conda\\envs\\langchian\\lib\\site-packages (from langchain-core<0.4,>=0.3.36->langchain-mcp-adapters) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\zata\\.conda\\envs\\langchian\\lib\\site-packages (from langchain-core<0.4,>=0.3.36->langchain-mcp-adapters) (4.13.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\zata\\.conda\\envs\\langchian\\lib\\site-packages (from langchain-core<0.4,>=0.3.36->langchain-mcp-adapters) (2.11.4)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\zata\\.conda\\envs\\langchian\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.36->langchain-mcp-adapters) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\zata\\.conda\\envs\\langchian\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.3.36->langchain-mcp-adapters) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\zata\\.conda\\envs\\langchian\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.3.36->langchain-mcp-adapters) (3.10.18)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\zata\\.conda\\envs\\langchian\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.3.36->langchain-mcp-adapters) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\zata\\.conda\\envs\\langchian\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.3.36->langchain-mcp-adapters) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\zata\\.conda\\envs\\langchian\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.3.36->langchain-mcp-adapters) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\zata\\.conda\\envs\\langchian\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.3.36->langchain-mcp-adapters) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\zata\\.conda\\envs\\langchian\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.3.36->langchain-mcp-adapters) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\zata\\.conda\\envs\\langchian\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.3.36->langchain-mcp-adapters) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\zata\\.conda\\envs\\langchian\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.3.36->langchain-mcp-adapters) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\zata\\.conda\\envs\\langchian\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.3.36->langchain-mcp-adapters) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\zata\\.conda\\envs\\langchian\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4,>=0.3.36->langchain-mcp-adapters) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\zata\\.conda\\envs\\langchian\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4,>=0.3.36->langchain-mcp-adapters) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\zata\\.conda\\envs\\langchian\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4,>=0.3.36->langchain-mcp-adapters) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\zata\\.conda\\envs\\langchian\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.3.36->langchain-mcp-adapters) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\zata\\.conda\\envs\\langchian\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.3.36->langchain-mcp-adapters) (2.4.0)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-2.0.25-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting langgraph-prebuilt>=0.1.8 (from langgraph)\n",
      "  Downloading langgraph_prebuilt-0.1.8-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting langgraph-sdk>=0.1.42 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.1.66-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting xxhash<4.0.0,>=3.5.0 (from langgraph)\n",
      "  Downloading xxhash-3.5.0-cp313-cp313-win_amd64.whl.metadata (13 kB)\n",
      "Collecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph)\n",
      "  Downloading ormsgpack-1.9.1-cp313-cp313-win_amd64.whl.metadata (44 kB)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in c:\\users\\zata\\.conda\\envs\\langchian\\lib\\site-packages (from mcp>=1.7->langchain-mcp-adapters) (0.4.0)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in c:\\users\\zata\\.conda\\envs\\langchian\\lib\\site-packages (from mcp>=1.7->langchain-mcp-adapters) (2.9.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in c:\\users\\zata\\.conda\\envs\\langchian\\lib\\site-packages (from mcp>=1.7->langchain-mcp-adapters) (0.0.20)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in c:\\users\\zata\\.conda\\envs\\langchian\\lib\\site-packages (from mcp>=1.7->langchain-mcp-adapters) (2.3.4)\n",
      "Requirement already satisfied: starlette>=0.27 in c:\\users\\zata\\.conda\\envs\\langchian\\lib\\site-packages (from mcp>=1.7->langchain-mcp-adapters) (0.46.2)\n",
      "Requirement already satisfied: uvicorn>=0.23.1 in c:\\users\\zata\\.conda\\envs\\langchian\\lib\\site-packages (from mcp>=1.7->langchain-mcp-adapters) (0.34.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\zata\\.conda\\envs\\langchian\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.3.36->langchain-mcp-adapters) (1.3.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\zata\\.conda\\envs\\langchian\\lib\\site-packages (from pydantic-settings>=2.5.2->mcp>=1.7->langchain-mcp-adapters) (1.1.0)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\zata\\.conda\\envs\\langchian\\lib\\site-packages (from uvicorn>=0.23.1->mcp>=1.7->langchain-mcp-adapters) (8.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\zata\\.conda\\envs\\langchian\\lib\\site-packages (from click>=7.0->uvicorn>=0.23.1->mcp>=1.7->langchain-mcp-adapters) (0.4.6)\n",
      "Downloading langgraph-0.4.3-py3-none-any.whl (151 kB)\n",
      "Downloading langgraph_checkpoint-2.0.25-py3-none-any.whl (42 kB)\n",
      "Downloading ormsgpack-1.9.1-cp313-cp313-win_amd64.whl (125 kB)\n",
      "Downloading xxhash-3.5.0-cp313-cp313-win_amd64.whl (30 kB)\n",
      "Downloading langgraph_prebuilt-0.1.8-py3-none-any.whl (25 kB)\n",
      "Downloading langgraph_sdk-0.1.66-py3-none-any.whl (47 kB)\n",
      "Installing collected packages: xxhash, ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
      "\n",
      "   ------------- -------------------------- 2/6 [langgraph-sdk]\n",
      "   ------------- -------------------------- 2/6 [langgraph-sdk]\n",
      "   -------------------- ------------------- 3/6 [langgraph-checkpoint]\n",
      "   --------------------------------- ------ 5/6 [langgraph]\n",
      "   --------------------------------- ------ 5/6 [langgraph]\n",
      "   --------------------------------- ------ 5/6 [langgraph]\n",
      "   --------------------------------- ------ 5/6 [langgraph]\n",
      "   ---------------------------------------- 6/6 [langgraph]\n",
      "\n",
      "Successfully installed langgraph-0.4.3 langgraph-checkpoint-2.0.25 langgraph-prebuilt-0.1.8 langgraph-sdk-0.1.66 ormsgpack-1.9.1 xxhash-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-mcp-adapters langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8de42d9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_mcp_adapters.langgraph'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01magents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AgentExecutor, create_tool_calling_agent\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprompts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatPromptTemplate\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_mcp_adapters\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlanggraph\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MCPClient\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# 替换为你 MCP 服务器的启动命令和工作目录\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# 由于我们使用 stdio，客户端需要启动服务器进程\u001b[39;00m\n\u001b[32m     10\u001b[39m MCP_SERVER_COMMAND = [\u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmcp_server.py\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;66;03m# 确保 mcp_server.py 在你的PYTHONPATH中或指定完整路径\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain_mcp_adapters.langgraph'"
     ]
    }
   ],
   "source": [
    "# langchain_mcp_client.py\n",
    "import asyncio\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_mcp_adapters.langgraph import MCPClient\n",
    "\n",
    "# 替换为你 MCP 服务器的启动命令和工作目录\n",
    "# 由于我们使用 stdio，客户端需要启动服务器进程\n",
    "MCP_SERVER_COMMAND = [\"python\", \"mcp_server.py\"] # 确保 mcp_server.py 在你的PYTHONPATH中或指定完整路径\n",
    "MCP_SERVER_CWD = \".\" # 服务器的工作目录\n",
    "\n",
    "async def main():\n",
    "    print(\"[LangChain Client] Initializing...\")\n",
    "\n",
    "    # 1. 初始化 LLM\n",
    "    llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "    # 2. 初始化 MCPClient\n",
    "    # MCPClient 会启动并管理 MCP 服务器进程 (如果使用 stdio)\n",
    "    # 它会发现服务器提供的工具\n",
    "    mcp_client = MCPClient(\n",
    "        name=\"math_solver\", # 给这个客户端实例一个名字\n",
    "        cmd=MCP_SERVER_COMMAND,\n",
    "        cwd=MCP_SERVER_CWD,\n",
    "        # verbose=True # 取消注释以获取更多调试信息\n",
    "    )\n",
    "\n",
    "    print(\"[LangChain Client] Connecting to MCP server and fetching tools...\")\n",
    "    try:\n",
    "        # 连接到服务器并获取工具\n",
    "        # 对于 stdio 传输，这会启动服务器子进程\n",
    "        await mcp_client.connect()\n",
    "        mcp_tools = await mcp_client.get_tools()\n",
    "    except Exception as e:\n",
    "        print(f\"[LangChain Client] Error connecting to MCP server or getting tools: {e}\")\n",
    "        await mcp_client.disconnect() # 清理\n",
    "        return\n",
    "\n",
    "    if not mcp_tools:\n",
    "        print(\"[LangChain Client] No tools found from MCP server.\")\n",
    "        await mcp_client.disconnect()\n",
    "        return\n",
    "\n",
    "    print(f\"[LangChain Client] Successfully fetched {len(mcp_tools)} tools from MCP server:\")\n",
    "    for tool in mcp_tools:\n",
    "        print(f\"  - Tool Name: {tool.name}, Description: {tool.description}\")\n",
    "\n",
    "    # 3. 创建 LangChain Agent\n",
    "    # 定义提示 (Prompt)\n",
    "    # 注意: 我们需要确保提示能够引导 LLM 使用提供的工具。\n",
    "    # \"agent_scratchpad\" 用于存储代理的中间思考和行动。\n",
    "    # \"input\" 是用户的原始输入。\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"You are a helpful assistant that can use tools to perform calculations. Use the available tools to answer the user's questions.\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "            (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # 创建 Tool Calling Agent\n",
    "    # 这个代理类型擅长决定何时以及如何调用工具\n",
    "    agent = create_tool_calling_agent(llm, mcp_tools, prompt)\n",
    "\n",
    "    # 创建 Agent Executor\n",
    "    # AgentExecutor 负责实际运行代理、调用工具并获取最终响应\n",
    "    agent_executor = AgentExecutor(agent=agent, tools=mcp_tools, verbose=True)\n",
    "\n",
    "    # 4. 调用代理\n",
    "    print(\"\\n[LangChain Client] Asking agent to solve 'What is 5 + 3?'\")\n",
    "    response1 = await agent_executor.ainvoke({\"input\": \"What is 5 + 3?\"})\n",
    "    print(f\"\\n[LangChain Client] Agent Response 1: {response1['output']}\")\n",
    "\n",
    "    print(\"\\n[LangChain Client] Asking agent to solve 'What is 7 multiplied by 4?'\")\n",
    "    response2 = await agent_executor.ainvoke({\"input\": \"What is 7 multiplied by 4?\"})\n",
    "    print(f\"\\n[LangChain Client] Agent Response 2: {response2['output']}\")\n",
    "\n",
    "    print(\"\\n[LangChain Client] Asking agent to solve 'What is (10 + 5) * 2?'\")\n",
    "    response3 = await agent_executor.ainvoke({\"input\": \"What is (10 + 5) * 2? First add 10 and 5, then multiply the result by 2.\"})\n",
    "    print(f\"\\n[LangChain Client] Agent Response 3: {response3['output']}\")\n",
    "\n",
    "    # 5. 清理\n",
    "    # 断开与 MCP 服务器的连接 (对于 stdio，这会终止服务器子进程)\n",
    "    print(\"[LangChain Client] Disconnecting from MCP server...\")\n",
    "    await mcp_client.disconnect()\n",
    "    print(\"[LangChain Client] Done.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1e7eb9",
   "metadata": {},
   "source": [
    "说明:\n",
    "\n",
    "MCP_SERVER_COMMAND: 定义了如何启动你的 MCP 服务器。由于 mcp_server.py 使用 stdio，LangChain 客户端 (MCPClient) 需要知道如何启动这个服务器脚本。\n",
    "MCPClient: 这是 langchain-mcp-adapters 提供的类，用于与 MCP 服务器交互。\n",
    "cmd 和 cwd: 指定了启动服务器的命令和工作目录。\n",
    "mcp_client.connect(): 建立与服务器的连接。对于 stdio，它会启动 mcp_server.py 作为一个子进程。\n",
    "mcp_client.get_tools(): 从连接的 MCP 服务器检索可用工具列表。这些工具会自动转换为 LangChain Tool 对象。\n",
    "ChatOpenAI: 我们使用的 LLM 实例。\n",
    "create_tool_calling_agent 和 AgentExecutor: 这些是 LangChain 中用于创建和运行能够使用工具的代理的标准组件。代理会接收用户输入，通过 LLM 决定是否以及如何使用 mcp_tools 中的工具，然后执行这些工具并返回最终答案。\n",
    "agent_executor.ainvoke(): 异步调用代理来处理输入。\n",
    "mcp_client.disconnect(): 关闭与 MCP 服务器的连接，并（在 stdio 模式下）终止服务器子进程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db3796e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21789ebf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60f28951",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a938a445",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667fbf2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Langchian",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
